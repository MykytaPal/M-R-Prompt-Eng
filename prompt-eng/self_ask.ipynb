{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Self-Ask Prompting**\n",
    "\n",
    "Self-Ask is a variation of zero-shot prompting where the model is made to **assume ownership of the task** rather than just assisting a user. Instead of instructing the model as if you are the developer, you reframe the prompt so that the model believes **it is the one building the solution**.\n",
    "\n",
    "By shifting the perspective, Self-Ask encourages the model to think more proactively, structuring responses with greater confidence and autonomy.\n",
    "\n",
    "In this approach:\n",
    "- Instead of saying, **\"Help me build a chatbot\"**,  \n",
    "- You say, **\"You are building a chatbot. How would you approach it?\"**  \n",
    "\n",
    "This subtle rewording makes the model **engage as the problem-solver** rather than just an assistant.\n",
    "\n",
    "## **Why Self-Ask Works**\n",
    "- Encourages the model to think step-by-step and plan.\n",
    "- Generates more structured and confident responses.\n",
    "- Useful for designing complex systems, software development, and decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nYou are developing a document analysis bot. \\nThink step-by-step about how you would design it.\\n\\n### Your task:\\n1. Identify the main features.\\n2. Explain the system architecture.\\n3. Provide implementation details.\\n\\n### Features:\\n- Upload documents (PDF, DOCX, TXT).\\n- Extract insights, summarize content, and answer queries.\\n\\nAfter reasoning through the design, provide a structured implementation approach.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 512, 'num_predict': 500}}\n",
      "**System Design: Document Analysis Bot**\n",
      "\n",
      "The document analysis bot aims to extract insights from uploaded documents, summarize their content, and answer user queries. Here's a step-by-step guide to designing the system:\n",
      "\n",
      "### Main Features\n",
      "\n",
      "1. **Document Upload**: Allow users to upload PDF, DOCX, or TXT files.\n",
      "2. **Insight Extraction**: Use Natural Language Processing (NLP) techniques to extract relevant insights from uploaded documents.\n",
      "3. **Content Summarization**: Provide a summary of the document's content, highlighting key points and main ideas.\n",
      "4. **Query Answering**: Allow users to ask questions about the document's content and provide answers based on extracted insights.\n",
      "\n",
      "### System Architecture\n",
      "\n",
      "The system architecture consists of the following components:\n",
      "\n",
      "1. **Frontend**:\n",
      "\t* User Interface (UI): A web-based interface for uploading documents, asking queries, and viewing results.\n",
      "\t* Client-side JavaScript: Handles user input, uploads, and displays initial results.\n",
      "2. **Backend**:\n",
      "\t* Document Processing: Uses NLP libraries to extract insights and summarize content.\n",
      "\t* Database: Stores extracted insights and summary data for later use or querying.\n",
      "\t* API Gateway: Handles incoming requests from the frontend, routes them to appropriate backend services.\n",
      "3. **NLP Engine**:\n",
      "\t* Natural Language Processing (NLP) library (e.g., spaCy, Stanford CoreNLP): Analyzes uploaded documents to extract insights and summarize content.\n",
      "\n",
      "### Implementation Details\n",
      "\n",
      "1. **Document Upload**:\n",
      "\t* Use a library like `jsPDF` or `pdfMake` for PDF uploads.\n",
      "\t* For DOCX and TXT files, use libraries like `docx.js` or `txt2html`.\n",
      "2. **Insight Extraction**:\n",
      "\t* Utilize NLP libraries to extract entities, sentiment, and keywords from uploaded documents.\n",
      "\t* Implement Named Entity Recognition (NER) to identify specific entities mentioned in the document.\n",
      "3. **Content Summarization**:\n",
      "\t* Use TextRank or Latent Semantic Analysis (LSA) algorithms to generate a summary of key points.\n",
      "4. **Database Storage**:\n",
      "\t* Design a database schema to store extracted insights and summary data, including metadata like document IDs and timestamps.\n",
      "\n",
      "Example Code:\n",
      "\n",
      "```javascript\n",
      "// Frontend (Client-side JavaScript)\n",
      "const uploadDocument = async (file) => {\n",
      "  // Use jsPDF library for PDF uploads\n",
      "  const pdfReader = new jsPDF();\n",
      "  pdfReader.add\n",
      "Time taken: 22.264s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## ZERO SHOT PROMPTING\n",
    "##\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbound Prompt ####\n",
    "MESSAGE = \"\"\"\n",
    "You are developing a document analysis bot. \n",
    "Think step-by-step about how you would design it.\n",
    "\n",
    "### Your task:\n",
    "1. Identify the main features.\n",
    "2. Explain the system architecture.\n",
    "3. Provide implementation details.\n",
    "\n",
    "### Features:\n",
    "- Upload documents (PDF, DOCX, TXT).\n",
    "- Extract insights, summarize content, and answer queries.\n",
    "\n",
    "After reasoning through the design, provide a structured implementation approach.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#### (2) Apply the Prompt ####\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model Request ####\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=512, \n",
    "                         num_predict=500)\n",
    "\n",
    "### Execute the Model Request ###\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "#excecuted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to improve it?\n",
    "\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
