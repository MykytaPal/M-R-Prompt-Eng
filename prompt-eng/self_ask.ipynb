{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Self-Ask Prompting**\n",
    "\n",
    "Self-Ask is a variation of zero-shot prompting where the model is made to **assume ownership of the task** rather than just assisting a user. Instead of instructing the model as if you are the developer, you reframe the prompt so that the model believes **it is the one building the solution**.\n",
    "\n",
    "By shifting the perspective, Self-Ask encourages the model to think more proactively, structuring responses with greater confidence and autonomy.\n",
    "\n",
    "In this approach:\n",
    "- Instead of saying, **\"Help me build a chatbot\"**,  \n",
    "- You say, **\"You are building a chatbot. How would you approach it?\"**  \n",
    "\n",
    "This subtle rewording makes the model **engage as the problem-solver** rather than just an assistant.\n",
    "\n",
    "## **Why Self-Ask Works**\n",
    "- Encourages the model to think step-by-step and plan.\n",
    "- Generates more structured and confident responses.\n",
    "- Useful for designing complex systems, software development, and decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nYou are developing a document analysis bot. \\nThink step-by-step about how you would design it and perform a Requirement Analysis for the project.\\n\\n### Your task:\\n1. Identify the main features.\\n2. Explain the system architecture and supporting functionalities.\\n\\n### Features (including but not limited to):\\n- Upload documents (PDF, DOCX, TXT).\\n- Extract insights, summarize content, and answer queries.\\n', 'stream': False, 'options': {'temperature': 0.5, 'num_ctx': 512, 'num_predict': 500}}\n",
      "**Document Analysis Bot Requirement Analysis**\n",
      "\n",
      "**Introduction:**\n",
      "The document analysis bot aims to provide a user-friendly interface for uploading various types of documents (PDF, DOCX, TXT) and extracting valuable insights from them. The system will perform content summarization and answer user queries related to the uploaded documents.\n",
      "\n",
      "**Main Features:**\n",
      "\n",
      "1. **Document Upload:**\n",
      "\t* Users can upload documents in PDF, DOCX, or TXT format.\n",
      "\t* Document size limit: 50MB\n",
      "\t* File type validation (only accepted formats)\n",
      "2. **Insight Extraction:**\n",
      "\t* Natural Language Processing (NLP) algorithms will be used to extract insights from the uploaded documents.\n",
      "\t* Insights can include:\n",
      "\t\t+ Key phrases and sentences\n",
      "\t\t+ Sentiment analysis (positive, negative, neutral)\n",
      "\t\t+ Entity extraction (people, places, organizations)\n",
      "3. **Content Summarization:**\n",
      "\t* The system will provide a summary of the document's content, including:\n",
      "\t\t+ Brief overview\n",
      "\t\t+ Main points\n",
      "\t\t+ Key takeaways\n",
      "4. **Query Answering:**\n",
      "\t* Users can ask questions related to the uploaded documents.\n",
      "\t* The system will respond with answers based on the extracted insights and content summarization.\n",
      "\n",
      "**System Architecture:**\n",
      "\n",
      "1. **Frontend:**\n",
      "\t* User interface built using HTML, CSS, and JavaScript.\n",
      "\t* Frontend framework (e.g., React, Angular) for efficient rendering and user interaction.\n",
      "2. **Backend:**\n",
      "\t* Server-side programming language (e.g., Python, Node.js) for handling requests and responses.\n",
      "\t* Backend framework (e.g., Django, Express.js) for routing, middleware, and database interactions.\n",
      "3. **Database:**\n",
      "\t* Relational database management system (RDBMS) for storing document metadata and extracted insights.\n",
      "\t* Database schema will include fields for:\n",
      "\t\t+ Document ID\n",
      "\t\t+ File type\n",
      "\t\t+ Upload date\n",
      "\t\t+ Summary\n",
      "\t\t+ Insights (e.g., sentiment, entity extraction)\n",
      "4. **API Gateway:**\n",
      "\t* API gateway layer to handle incoming requests and route them to the appropriate backend services.\n",
      "5. **Machine Learning Services:**\n",
      "\t* Natural Language Processing (NLP) library for text analysis and insights extraction.\n",
      "\t* Machine learning framework (e.g., TensorFlow, PyTorch) for building and training models.\n",
      "\n",
      "**Deployment:**\n",
      "\n",
      "1.\n",
      "Time taken: 6.041s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## SELF ASK PROMPTING (Based on Zero-Shot)\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbound Prompt ####\n",
    "MESSAGE = \"\"\"\n",
    "You are developing a document analysis bot. \n",
    "Think step-by-step about how you would design it and perform a Requirement Analysis for the project.\n",
    "\n",
    "### Your task:\n",
    "1. Identify the main features.\n",
    "2. Explain the system architecture and supporting functionalities.\n",
    "\n",
    "### Features (including but not limited to):\n",
    "- Upload documents (PDF, DOCX, TXT).\n",
    "- Extract insights, summarize content, and answer queries.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#### (2) Apply the Prompt ####\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model Request ####\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.5, \n",
    "                         num_ctx=512, \n",
    "                         num_predict=500)\n",
    "\n",
    "### Execute the Model Request ###\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "#excecuted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance and Behavior:\n",
    "\n",
    "This prompting technique performed surprisingly well. Using this approach, we were able to consistently generate an elaborate Requirement Analysis document in a specified format, including a list of all major features and required supporting functionalities.\n",
    "\n",
    "Interestingly, temperature had minimal impact on this technique, as we obtained similar results at both lower and higher temperatures.\n",
    "\n",
    "A context window of around 500 produced decent results, meaning it was sufficient to process the prompt and generate a Requirement Analysis. However, reducing it further led to some inconsistent results.\n",
    "\n",
    "Setting the Maximum Number of Tokens to 500 allowed for a detailed list to be generated without unnecessary bloating. Increasing this number had two effects: either we received a more detailed analysis, or the response became bloated with irrelevant information that had not been requested, making 500 a reasonable compromise.\n",
    "\n",
    "## Limitations:\n",
    "\n",
    "This implementation of self ask prompting is not without its limitations:\n",
    "\n",
    "1. It relies on the LLaMA 3.2 model, which has a limited data pool and reasoning capabilities.\n",
    "2. We are unable to fine-tune the prompt, leaving the Requirement Analysis almost entirely up to the AI, which sometimes results in inconsistent or suboptimal results.\n",
    "3. It occasionally generates redundant or irrelevant sub-questions.\n",
    "4. It is difficult to implement for continuous conversations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
