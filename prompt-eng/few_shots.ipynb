{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shots Prompting\n",
    "\n",
    "Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.\n",
    "\n",
    "## References:\n",
    "* [Touvron et al. 2023](https://arxiv.org/pdf/2302.13971.pdf): present few shot properties  when models were scaled to a sufficient size\n",
    "* [Kaplan et al., 2020](https://arxiv.org/abs/2001.08361)\n",
    "* [Brown et al. 2020](https://arxiv.org/abs/2005.14165)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Ffew_shots.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nYou are an AI document analysis assistant. Below are some examples:\\n\\nExample 1:\\nInput: \"Summarize the document about climate change.\"\\nOutput: \"The document discusses the impact of greenhouse gases, global warming, and mitigation strategies.\"\\n\\nExample 2:\\nInput: \"Extract key topics from a financial report.\"\\nOutput: \"Revenue growth, market trends, investment risks, cost analysis.\"\\n\\nExample 3:\\nInput: \"Provide insights from a research paper on AI ethics.\"\\nOutput: \"Ethical considerations in AI, bias in machine learning, responsible AI frameworks.\"\\n\\nNow, analyze the document and provide a structured response:\\n\\nAnalyze the provided document and summarize its key points.', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "Based on the available information, I'll create a summary of the document.\n",
      "\n",
      "**Summary**\n",
      "\n",
      "The document appears to be a written task that requires analysis and summarization of the provided text. The task involves extracting key points from the text and rephrasing them in a concise manner.\n",
      "\n",
      "Unfortunately, there is no explicit content to analyze. The prompt instructs me to follow a specific format but does not provide any additional context or information about the topic to be summarized.\n",
      "\n",
      "If you could provide more details or clarify\n",
      "Time taken: 4.794s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## FEW SHOTS PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"Analyze the provided document and summarize its key points.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "FEW_SHOT = \"\"\"\n",
    "You are an AI document analysis assistant. Below are some examples:\n",
    "\n",
    "Example 1:\n",
    "Input: \"Summarize the document about climate change.\"\n",
    "Output: \"The document discusses the impact of greenhouse gases, global warming, and mitigation strategies.\"\n",
    "\n",
    "Example 2:\n",
    "Input: \"Extract key topics from a financial report.\"\n",
    "Output: \"Revenue growth, market trends, investment risks, cost analysis.\"\n",
    "\n",
    "Example 3:\n",
    "Input: \"Provide insights from a research paper on AI ethics.\"\n",
    "Output: \"Ethical considerations in AI, bias in machine learning, responsible AI frameworks.\"\n",
    "\n",
    "Now, analyze the document and provide a structured response:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = FEW_SHOT + '\\n' + MESSAGE\n",
    "\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve it?\n",
    "\n",
    "Following the findings from [Min et al. (2022)](https://arxiv.org/abs/2202.12837), here are a few more tips about demonstrations/exemplars when doing few-shot:\n",
    "\n",
    "* \"the label space and the distribution of the input text specified by the demonstrations are both important (regardless of whether the labels are correct for individual inputs)\"\n",
    "* the format you use also plays a key role in performance, even if you just use random labels, this is much better than no labels at all.\n",
    "* additional results show that selecting random labels from a true distribution of labels (instead of a uniform distribution) also helps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
