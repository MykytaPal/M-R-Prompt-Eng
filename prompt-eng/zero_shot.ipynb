{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting refers to a technique in prompt engineering where you provide a model with a task without any prior examples. The model is expected to understand and generate a response or complete the task purely based on the given instruction.\n",
    "\n",
    "In other words, the model is given \"zero\" prior training examples or demonstrations in the prompt and relies on its pre-trained knowledge to infer what is needed.\n",
    "\n",
    "## References:\n",
    "* [Wei et al. (2022)](https://arxiv.org/pdf/2109.01652.pdf): demonstrate how instruction tuning improves zero-shot learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 771 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 935 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: idna, certifi, charset-normalizer, urllib3, requests\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.2.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/anan/.pyenv/versions/3.7.3/envs/Django/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nYou are a requirements analyst. Define user interactions and functionalities for a **document analysis bot**.\\n\\n### **Objective**:\\nThe bot should:\\n- Allow users to upload documents (PDF, DOCX, TXT).\\n- Extract insights, summarize content, and answer queries.\\n\\n### **Deliverables**:\\nProvide a **structured requirement analysis** covering:\\n\\n1. **User Interactions**:\\n   - Uploading files.\\n   - Asking questions about document content.\\n   - Requesting summaries, keyword extraction, and topic analysis.\\n   - Searching for specific information.\\n   - Receiving system feedback.\\n\\n2. **Functional Capabilities**:\\n   - Support multiple file formats and extract text.\\n   - Perform NLP-based analysis (summarization, entity recognition).\\n   - Enable keyword-based and semantic search.\\n   - Provide error handling and feedback.\\n   - Integrate with messaging platforms like Discord.\\n\\nFormat the response as a **structured bullet-point list**.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 512, 'num_predict': 500}}\n",
      "Here is a structured requirement analysis for the document analysis bot:\n",
      "\n",
      "### User Interactions\n",
      "\n",
      "* **Upload File**\n",
      "\t+ Users can upload documents (PDF, DOCX, TXT) through a secure file transfer protocol (FTP/SFTP).\n",
      "\t+ The system should validate file formats and ensure only approved types are accepted.\n",
      "\t+ A progress bar or loading indicator should be displayed during the upload process.\n",
      "* **Ask Question about Document Content**\n",
      "\t+ Users can ask questions about document content using natural language input (e.g., \"What is the main topic of this report?\").\n",
      "\t+ The system should use NLP to understand and respond to user queries accurately.\n",
      "\t+ Response should be provided in a clear and concise manner, with relevant supporting evidence from the document.\n",
      "* **Request Summaries, Keyword Extraction, and Topic Analysis**\n",
      "\t+ Users can request summaries of the document's main points, key takeaways, or overall content.\n",
      "\t+ The system should perform entity recognition to extract specific keywords and phrases.\n",
      "\t+ Topic analysis should be performed using NLP techniques to identify dominant themes and concepts.\n",
      "* **Search for Specific Information**\n",
      "\t+ Users can search for specific information within the document using keywords, phrases, or entities extracted during processing.\n",
      "\t+ Results should be presented in a clear and organized manner, with relevant context and supporting evidence from the document.\n",
      "* **Receive System Feedback**\n",
      "\t+ The system should provide feedback to users on the success of their queries, including any errors or limitations encountered.\n",
      "\t+ Feedback should be provided in a transparent and understandable manner, with suggestions for improvement or next steps.\n",
      "\n",
      "Example Use Cases:\n",
      "\n",
      "1. A researcher wants to analyze a large report and identify key concepts and entities. They can upload the document and ask questions like \"What are the main topics discussed in this report?\" or \"Who is the author of this report?\"\n",
      "2. A student needs help understanding a complex academic paper. They can upload the paper and ask questions like \"What is the main argument presented in this paper?\" or \"Can you summarize the key points for me?\"\n",
      "3. A business professional wants to quickly scan a large document to identify relevant information. They can upload the document and use the search function to find specific keywords, phrases, or entities.\n",
      "\n",
      "Functional Requirements:\n",
      "\n",
      "1. User authentication and authorization\n",
      "2. Document upload and validation\n",
      "3. NLP processing for natural language input and output\n",
      "4. Search functionality with relevance ranking\n",
      "5. Entity recognition and extraction\n",
      "6. Topic\n",
      "Time taken: 25.226s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## ZERO SHOT PROMPTING\n",
    "##\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbound Prompt ####\n",
    "MESSAGE = \"\"\"\n",
    "You are a requirements analyst. Define user interactions and functionalities for a **document analysis bot**.\n",
    "\n",
    "### **Objective**:\n",
    "The bot should:\n",
    "- Allow users to upload documents (PDF, DOCX, TXT).\n",
    "- Extract insights, summarize content, and answer queries.\n",
    "\n",
    "### **Deliverables**:\n",
    "Provide a **structured requirement analysis** covering:\n",
    "\n",
    "1. **User Interactions**:\n",
    "   - Uploading files.\n",
    "   - Asking questions about document content.\n",
    "   - Requesting summaries, keyword extraction, and topic analysis.\n",
    "   - Searching for specific information.\n",
    "   - Receiving system feedback.\n",
    "\n",
    "2. **Functional Capabilities**:\n",
    "   - Support multiple file formats and extract text.\n",
    "   - Perform NLP-based analysis (summarization, entity recognition).\n",
    "   - Enable keyword-based and semantic search.\n",
    "   - Provide error handling and feedback.\n",
    "   - Integrate with messaging platforms like Discord.\n",
    "\n",
    "Format the response as a **structured bullet-point list**.\n",
    "\"\"\"\n",
    "\n",
    "#### (2) Apply the Prompt ####\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model Request ####\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=512, \n",
    "                         num_predict=500)\n",
    "\n",
    "### Execute the Model Request ###\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to improve it?\n",
    "\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
